{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming is the process of reducing a word to its root form by removing prefixes or suffixes. It's commonly used in Natural Language Processing (NLP) to simplify words and improve text analysis.\n",
    "\n",
    "For example:\n",
    "\n",
    "\"running\" → \"run\"\n",
    "\"flies\" → \"fli\"\n",
    "\"happily\" → \"happili\"\n",
    "Why Use Stemming?\n",
    "Reduces vocabulary size.\n",
    "Helps in matching similar words in text search or analysis.\n",
    "Useful in applications like search engines, text classification, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=['eating','eats','eaten','writting','writes','programming','program','history','finally']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## porter stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[43mwords\u001b[49m:\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(word +\u001b[33m'\u001b[39m\u001b[33m---->\u001b[39m\u001b[33m'\u001b[39m+stemming.stem(word))\n",
      "\u001b[31mNameError\u001b[39m: name 'words' is not defined"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word +'---->'+stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('congratulations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reggexp Stemmer class\n",
    "\n",
    "The RegexpStemmer class in NLTK (Natural Language Toolkit) is a type of stemmer that uses regular expressions to identify and remove word suffixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "\n",
    "reg_x=RegexpStemmer('ing$|s$|able$',min=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_x.stem('eating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SNOWBALL STEMER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Snowball Stemmer is a powerful and flexible stemming algorithm used in NLP (Natural Language Processing). It’s part of the NLTK library in Python and is often preferred over the Porter Stemmer due to its improved efficiency and support for multiple languages.\n",
    "\n",
    "Key Features of Snowball Stemmer:\n",
    "Supports multiple languages like English, Spanish, German, etc.\n",
    "More aggressive and effective in reducing words to their root form compared to the Porter Stemmer.\n",
    "Developed by Martin Porter as an improvement to the original Porter Stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snow=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating -----> eat\n",
      "eats -----> eat\n",
      "eaten -----> eaten\n",
      "writting -----> writ\n",
      "writes -----> write\n",
      "programming -----> program\n",
      "program -----> program\n",
      "history -----> histori\n",
      "finally -----> final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + ' -----> ' + snow.stem(word))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
