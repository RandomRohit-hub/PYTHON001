{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "message=pd.read_csv('spamclassifier/sms collection/smsspamcollection',sep='\\t',names=[\"label\",\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ham</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>spam</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>spam</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>spam</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>spam</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ham</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ham</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>spam</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ham</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ham</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                label  message\n",
       "0                                                 ham      NaN\n",
       "1                       Ok lar... Joking wif u oni...      NaN\n",
       "2                                                spam      NaN\n",
       "3   Free entry in 2 a wkly comp to win FA Cup fina...      NaN\n",
       "4                                                 ham      NaN\n",
       "5   U dun say so early hor... U c already then say...      NaN\n",
       "6                                                 ham      NaN\n",
       "7   Nah I don't think he goes to usf, he lives aro...      NaN\n",
       "8                                                spam      NaN\n",
       "9   FreeMsg Hey there darling it's been 3 week's n...      NaN\n",
       "10                                                ham      NaN\n",
       "11  Even my brother is not like to speak with me. ...      NaN\n",
       "12                                                ham      NaN\n",
       "13  As per your request 'Melle Melle (Oru Minnamin...      NaN\n",
       "14                                               spam      NaN\n",
       "15  WINNER!! As a valued network customer you have...      NaN\n",
       "16                                               spam      NaN\n",
       "17  Had your mobile 11 months or more? U R entitle...      NaN\n",
       "18                                                ham      NaN\n",
       "19  I'm gonna be home soon and i don't want to tal...      NaN\n",
       "20                                               spam      NaN\n",
       "21  SIX chances to win CASH! From 100 to 20,000 po...      NaN\n",
       "22                                               spam      NaN\n",
       "23  URGENT! You have won a 1 week FREE membership ...      NaN\n",
       "24                                                ham      NaN\n",
       "25  I've been searching for the right words to tha...      NaN\n",
       "26                                                ham      NaN\n",
       "27                I HAVE A DATE ON SUNDAY WITH WILL!!      NaN\n",
       "28                                               spam      NaN\n",
       "29  XXXMobileMovieClub: To use your credit, click ...      NaN\n",
       "30                                                ham      NaN\n",
       "31                         Oh k...i'm watching here:)      NaN\n",
       "32                                                ham      NaN\n",
       "33  Eh u remember how 2 spell his name... Yes i di...      NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data cleaning and preprocessing\n",
    "import re\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                    cleaned_message\n",
      "0    ham                              ok lar joke wif u oni\n",
      "1   spam  free entri wkli comp win fa cup final tkt st m...\n",
      "2    ham                u dun say earli hor u c alreadi say\n",
      "3    ham               nah think goe usf live around though\n",
      "4   spam           freemsg hey darl week word back like fun\n",
      "5   spam      even brother like speak treat like aid patent\n",
      "6    ham  per request mell mell oru minnaminungint nurun...\n",
      "7    ham  winner valu network custom select receivea pri...\n",
      "8   spam  mobil month u r entitl updat latest colour mob...\n",
      "9   spam  gonna home soon want talk stuff anymor tonight...\n",
      "10   ham  six chanc win cash pound txt csh send cost p d...\n",
      "11  spam  urgent week free membership prize jackpot txt ...\n",
      "12  spam  search right word thank breather promis wont t...\n",
      "13   ham                                        date sunday\n",
      "14   ham  xxxmobilemovieclub use credit click wap link n...\n",
      "15  spam                                         oh k watch\n",
      "16   ham     eh u rememb spell name ye v naughti make v wet\n",
      "17   ham                final messag make list length equal\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Initialize Stemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Ensure data has the same number of items\n",
    "data = {\n",
    "    \"label\": [\"ham\", \"spam\", \"ham\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\", \"spam\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\", \"spam\", \"ham\", \"ham\"],  # 18 items\n",
    "    \"message\": [\n",
    "        \"Ok lar... Joking wif u oni...\",\n",
    "        \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entr...\",\n",
    "        \"U dun say so early hor... U c already then say...\",\n",
    "        \"Nah I don't think he goes to usf, he lives around here though\",\n",
    "        \"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it s...\",\n",
    "        \"Even my brother is not like to speak with me. They treat me like aids patent.\",\n",
    "        \"As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertu...\",\n",
    "        \"WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim...\",\n",
    "        \"Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera f...\",\n",
    "        \"I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enou...\",\n",
    "        \"SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6day...\",\n",
    "        \"URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to ...\",\n",
    "        \"I've been searching for the right words to thank you for this breather. I promise i wont take your h...\",\n",
    "        \"I HAVE A DATE ON SUNDAY WITH WILL!!\",\n",
    "        \"XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> h...\",\n",
    "        \"Oh k...i'm watching here:)\",\n",
    "        \"Eh u remember how 2 spell his name... Yes i did. He v naughty make until i v wet.\",\n",
    "        \"Final message to make list lengths equal\"  # This ensures both lists are of length 18\n",
    "    ]  \n",
    "}\n",
    "\n",
    "# ✅ Check if both lists are the same length\n",
    "if len(data[\"label\"]) == len(data[\"message\"]):\n",
    "    df = pd.DataFrame(data)\n",
    "else:\n",
    "    print(\"Error: Mismatch in label and message count\")\n",
    "\n",
    "# Function to clean and preprocess text\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)  # Remove non-alphabet characters\n",
    "    words = text.split()  # Tokenize words\n",
    "    words = [ps.stem(word) for word in words if word not in stopwords.words('english')]  # Remove stopwords & stem\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply text cleaning if dataframe is successfully created\n",
    "if 'df' in locals():\n",
    "    df['cleaned_message'] = df['message'].apply(clean_text)\n",
    "    print(df[['label', 'cleaned_message']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer(max_features=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Iterable over raw text documents expected, string object received.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcleaned_message\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m.toarray()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\pynthon\\venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\pynthon\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1354\u001b[39m, in \u001b[36mCountVectorizer.fit_transform\u001b[39m\u001b[34m(self, raw_documents, y)\u001b[39m\n\u001b[32m   1350\u001b[39m \u001b[38;5;66;03m# We intentionally don't call the transform method to make\u001b[39;00m\n\u001b[32m   1351\u001b[39m \u001b[38;5;66;03m# fit_transform overridable without unwanted side effects in\u001b[39;00m\n\u001b[32m   1352\u001b[39m \u001b[38;5;66;03m# TfidfVectorizer.\u001b[39;00m\n\u001b[32m   1353\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(raw_documents, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1354\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1355\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIterable over raw text documents expected, string object received.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1356\u001b[39m     )\n\u001b[32m   1358\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_ngram_range()\n\u001b[32m   1359\u001b[39m \u001b[38;5;28mself\u001b[39m._warn_for_unused_params()\n",
      "\u001b[31mValueError\u001b[39m: Iterable over raw text documents expected, string object received."
     ]
    }
   ],
   "source": [
    "cv.fit_transform('cleaned_message').toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
